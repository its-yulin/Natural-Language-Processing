{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Vector Space Models\n",
    "\n",
    "This chapter discusses computational models to represent text in vector spaces.\n",
    "\n",
    "* [Preparation](#Preparation)\n",
    "* [Bag-of-Words](#Bag-of-Words)\n",
    "* [Frequency Counts](#Frequency-Counts)\n",
    "* [Exercise 1](#Exercise-1)\n",
    "* [TF-IDF](#TF-IDF)\n",
    "* [Similarity Metrics](#Similarity-Metrics)\n",
    "\n",
    "## References\n",
    "\n",
    "* [Vector Space Model](https://en.wikipedia.org/wiki/Vector_space_model)\n",
    "* [Bag-of-Words Model](https://en.wikipedia.org/wiki/Bag-of-words_model)\n",
    "* [TF-IDF](https://en.wikipedia.org/wiki/Tfâ€“idf)\n",
    "* [Euclidean Distance](https://en.wikipedia.org/wiki/Euclidean_distance)\n",
    "* [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Download [`aesopfables.json`](https://github.com/emory-courses/computational-linguistics/blob/master/docs/res/aesopfables.json) and read the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\codfi\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\codfi\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\codfi\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\codfi\\anaconda3\\lib\\site-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\codfi\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\codfi\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "import requests\n",
    "\n",
    "def download(remote_addr: str, local_addr: str):\n",
    "    r = requests.get(remote_addr)\n",
    "    fin = open(local_addr, 'wb')\n",
    "    fin.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [`requests`](https://requests.readthedocs.io/en/master/user/quickstart/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../res/vsm/aesopfables.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-df94fadfcf5b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0maesop_link\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'https://raw.githubusercontent.com/emory-courses/computational-linguistics/master/res/vsm/aesopfables.json'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0maesop_file\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'../res/vsm/aesopfables.json'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mdownload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maesop_link\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maesop_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-6-9b69b12c5554>\u001B[0m in \u001B[0;36mdownload\u001B[1;34m(remote_addr, local_addr)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mdownload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mremote_addr\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlocal_addr\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrequests\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mremote_addr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m     \u001B[0mfin\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlocal_addr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'wb'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m     \u001B[0mfin\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontent\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../res/vsm/aesopfables.json'"
     ]
    }
   ],
   "source": [
    "aesop_link = 'https://raw.githubusercontent.com/emory-courses/computational-linguistics/master/res/vsm/aesopfables.json'\n",
    "aesop_file = '../res/vsm/aesopfables.json'\n",
    "download(aesop_link, aesop_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make sure which directory `aesopfables.json` is downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../res/vsm/aesopfables.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-13a615746230>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mjson\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mfables\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maesop_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfables\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mfable\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfables\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfable\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'title'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../res/vsm/aesopfables.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "fables = json.load(open(aesop_file))\n",
    "\n",
    "print(len(fables))\n",
    "for fable in fables[:10]: print(fable['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bag-of-Words\n",
    "\n",
    "Let there be a giant bag that can hold all unique words in the world.\n",
    "Then, each token in a text such as \"*Jinho Choi is a professor at Emory University .*\" can be inserted to the bag as follows:\n",
    "\n",
    "<img src=\"res/bow.jpg\" width=600 align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "This bag can be represented by a vector of which every dimension stands for a unique token in the world.\n",
    "All dimensions are initialized to `0`, except for the ones representing tokens in the input text, which are assigned with `1`:\n",
    "\n",
    "<img src=\"res/vsm.jpg\" width=600 align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the total dimension of this vector?\n",
    "* Does this vector correctly represent the original text (anything missing)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bag-of-words can be implemented by a dictionary (representing a sparse vector), where the key is a term in the text and its value is always `1`.\n",
    "The value of every other term that does not appear in the document is assumed to be `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = {'Jinho': 1, 'Choi': 1, 'is': 1, 'a': 1, 'professor': 1, 'at': 1, 'Emory': 1, 'University': 1, '.': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Counts\n",
    "\n",
    "Consider the following two documents:\n",
    "\n",
    "```\n",
    "D1: John bought a car . The car was fancy .\n",
    "D2: Mary liked the car .  John gave it to Mary .\n",
    "```\n",
    "\n",
    "A **term frequency** (`tf`) is the number of occurrences of a specific term in a specific document:\n",
    "\n",
    "```\n",
    "tf(John, D1) = 1\n",
    "tf(John, D2) = 1\n",
    "tf(Mary, D2) = 2\n",
    "```\n",
    "\n",
    "A **document frequency** (`df`) is the number of documents containing a specific term:\n",
    "\n",
    "```\n",
    "df(John) = 2\n",
    "df(John) = 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the function `term_frequencies()` that takes `fables` above and returns a dictionary where each key-value pair represents the source and term frequencies of the corresponding document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import Dict\n",
    "\n",
    "def term_frequencies(fables) -> Dict[str, Counter]:\n",
    "    def key(t): return t[t.rfind('&')+1:]\n",
    "    return {key(fable['source']): Counter(fable['tokens'].split()) for fable in fables}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [`collections.Counter`](https://docs.python.org/3/library/collections.html#collections.Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = term_frequencies(fables)\n",
    "print(tfs['Androcles'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Let us define the function `document_frequencies()` that takes `fables` and returns a dictionary where each key-value pair represents a term and its document frequency:\n",
    "\n",
    "```python\n",
    "def document_frequencies(fables) -> Dict[str, int]:\n",
    "    # To be filled\n",
    "    return dict()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = document_frequencies(fables)\n",
    "print(dfs['Lion'], dfs['lion'])\n",
    "for term, count in sorted(dfs.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(term, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [sorted()](https://docs.python.org/3/library/functions.html?highlight=sorted#sorted)\n",
    "* [lambda](https://docs.python.org/3/reference/expressions.html#lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "What are important terms in a document?\n",
    "\n",
    "* High term frequency\n",
    "* low document frequency\n",
    "\n",
    "The $\\mathrm{tf}\\cdot\\mathrm{idf}_{t,d}$ (Term Frequency - Inverse Document Frequency) of a specific term $t$ in a specific document $d \\in D$ is measured as follows:\n",
    "\n",
    "$$\n",
    "\\mathrm{tf}\\cdot\\mathrm{idf}_{t,d} = \\mathrm{tf}_{t,d} \\times \\log\\frac{|D|}{\\mathrm{df}_t}\n",
    "$$\n",
    "\n",
    "Several variations of $\\mathrm{tf}_{t,d}$ have also been proposed using sublinear or normalization:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{wf}_{t,d} &=& \\left\\{\n",
    "\\begin{array}{cl}\n",
    " 1 + \\log\\mathrm{tf}_{t,d} & \\mbox{if $\\textrm{tf}_{t,d} > 0$}\\\\\n",
    " 0 & \\mbox{otherwise}\n",
    "\\end{array}\n",
    "\\right. \\\\\n",
    "\\mathrm{ntf}_{t,d} &=& \\alpha + (1-\\alpha)\\frac{\\mathrm{tf}_{t,d}}{\\mathrm{tf}_{\\mathrm{argmax}({\\mathrm{tf}_{\\forall t, d}}),d}}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the function `tf_idfs()` that takes `fables` and returns a dictionary where the key is a (term, document ID) pair, and the value is its TF-IDF score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import math\n",
    "\n",
    "def tf_idfs(fables) -> Dict[str, Dict[str, int]]:\n",
    "    tfs = term_frequencies(fables)\n",
    "    dfs = document_frequencies(fables)\n",
    "    out = dict()\n",
    "    D = len(tfs)\n",
    "\n",
    "    for dkey, term_counts in tfs.items():\n",
    "        out[dkey] = {t: tf * math.log(D / dfs[t]) for t, tf in term_counts.items()}\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfs = tf_idfs(fables)\n",
    "print(tfidfs['Androcles']['Lion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, score in sorted(tfs['Androcles'].items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print(t, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, score in sorted(tfidfs['Androcles'].items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print(t, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Metrics\n",
    "\n",
    "Given two vectors, $X_i = (x_{i1}, \\ldots, x_{in})$ and $X_j = (x_{j1}, \\ldots, x_{jn})$, the **Euclidean distance** between $X_i$ and $X_j$ measures the magnitude between them:\n",
    "\n",
    "$$\n",
    "\\mathrm{Euclidean}(X_i, X_j) = \\lVert X_i - X_j \\rVert = \\sqrt{\\sum_{k=1}^n (x_{ik} - x_{jk})^2}\n",
    "$$\n",
    "\n",
    "On the other hand, the **Cosine similarity** measures the angle difference between them:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathrm{Cosine}(X_i, X_j) = \\frac{X_i\\cdot X_j}{\\lVert X_i\\rVert\\lVert X_j\\rVert} = \\frac{\\sum_{\\forall k}(x_{ik} \\cdot x_{jk})}{\\sqrt{\\sum_{\\forall k}(x_{ik})^2} \\cdot \\sqrt{\\sum_{\\forall k}(x_{jk})^2}}\n",
    "$$\n",
    "\n",
    "<img src=\"res/vector_similarities.jpg\" width=350/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the function `euclidean(x1, x2)` that takes two sparse vectors, `x1` and `x2`, and returns their Euclidean distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(x1: Dict[str, float], x2: Dict[str, float]) -> float:\n",
    "    t = sum(((s1 - x2.get(term, 0)) ** 2 for term, s1 in x1.items()))\n",
    "    t += sum((s2 ** 2 for term, s2 in x2.items() if term not in x1))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tfidfs['Androcles']\n",
    "x2 = tfidfs['TheAntandtheChrysalis']\n",
    "x3 = tfidfs['TheAntsandtheGrasshopper']\n",
    "print(euclidean(x1, x2))\n",
    "print(euclidean(x2, x3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download another JSON file containing alternative Aesop's fables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://raw.githubusercontent.com/emory-courses/computational-linguistics/master/res/vsm/aesopfables-alt.json'\n",
    "file = '../res/vsm/aesopfables-alt.json'\n",
    "download(link, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fables_alt = json.load(open(file))\n",
    "for f in fables_alt: print(f['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_alt = tf_idfs(fables_alt)\n",
    "print(tfidf_alt.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Write a function `most_similar()` that takes a spare vector representation of a document and find the most similar fable among the ones in [aesopfables.json](https://github.com/emory-courses/computational-linguistics/blob/master/res/vsm/aesopfables.json).\n",
    "\n",
    "```python\n",
    "def most_similar(Y: Dict[str, Dict[str, float]], x: Dict[str, float]) -> str:\n",
    "    # To be filled\n",
    "    return ''\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, x in tfidf_alt.items():\n",
    "    t = most_similar(tfidfs, x)\n",
    "    print('{} -> {}'.format(k, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}